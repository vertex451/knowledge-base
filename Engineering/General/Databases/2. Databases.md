# Relational

## Cloud
### Amazon RDS

Similar to having DB within EC2, but reduces the management overhead. Amazon handles provisioning instances, replication and backups, maintenance and updates.

Supports 7 DB engines:
1. MySQL
2. PostgreSQL
3. MariaDB
4. Oracle
5. SQL Server
6. 7. Amazon Aurora (with both MySQL and PostgreSQL compatibility)

- Scalability(out of the box)
- Highly available service provisioning by availability zones and replication capabilities
- Auto backup and restore capabilities lead to increased consistency and durability of customer data.
### Amazon Aurora

In Amazon Aurora, the database storage and compute capacity are decoupled. This means that you can scale the compute capacity (CPU and memory) independently from the storage capacity.

Data is stored in a shared “cluster volume”, which spans six storage nodes and three availability zones. This gives you multi Avaiability Zones resilience, and it uses the same “pay for what you use” model as S3. Rather than provisioning storage upfront, the volume grows or shrinks to match your data, [up to 128TB](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_Limits.html#RDS_Limits.FileSize.Aurora)—and your bill grows or shrinks to match.

Queries are handled by compute nodes, which all talk to the same cluster volume. You have the same primary/replica split, but replication is handled entirely within the storage nodes. There’s no synchronous replication between compute nodes, and they don’t hold any permanent state.
 
**Cons**
- Tends to be slightly more expensive than Amazon RDS, but is typically easier to use, and provides higher reliability than non cloud-specialized solutions.
- Aurora only uses the InnoDB storage engine. You can’t use other storage engines.
#### Aurora Serverless
Aurora’s architecture enables another approach - serverless one:
- Storage scales to meet demand. 
- It automatically starts and stops Compute Nodes to match the needs of your application. It scales up to meet a spike in demand and scales down when things are quiet. The data remains in the shared storage volume, independent of any scaling.
### Redshift
A Redshift cluster is a fit for generating reports out of [large amounts of data](https://www.techtarget.com/searchdatamanagement/tip/Should-you-host-your-data-lake-in-the-cloud), such as site traffic reports, user activity, log analysis, market or business reports, billing analysis for large platforms and public data set analysis. The Redshift user might trigger report generation automatically with the expectation that it will take some time to process. Upon report completion, Redshift's output can be exported to a format where it can be accessed by other application components, such as business intelligence visualization tools, internal reports and online applications.

Benefits:
- Allows us to perform the execution of parallel queries across multiple system nodes.
- Provision of auto-Backup on Amazon S3.
- It is more cost-efficient when compared to other competitive data warehouse services.
- Provision of built-in security in the form of end-to-end encryption and user-configurable firewall rules.

## Non Cloud
### Postgres
Max text length of Varchar Data Type is 65.535kb
### MySQL
#### Storage Engines
A storage engine(Applicable to MySQL and MariaDB) - is the underlying software component that a database management system (DBMS) uses to create, read, update and delete (CRUD) data from a database.

Storage engine is responsible for the following features such as transaction support, row/table locking, crash recovery and multi-version concurrency control.

**The storage engine is specified at the time of the table creation.**
```mysql
mysql> CREATE TABLE Cars(Id INTEGER PRIMARY KEY, Name VARCHAR(50), 
    -> Cost INTEGER) ENGINE='MyISAM';
```
It is possible to migrate to a different storage engine. Note that migrating a large table might take a long time.

MySQL supported storage engines:
- InnoDB (default after MySQL 5.5, the most widely used storage engine with transaction support)
- MyISAM (is the original storage engine)
- Memory (It is the fastest engine, but data can be lost on restart)
- CSV (data in CSV format is easily integrated into other applications.)
- Merge (logically groups a series of identical MyISAM tables, and references them as one object)
- Archive (is optimised for high speed inserting, ideal for storing historical data)
- Federated (good for distributed systems since it separates MySQL servers to create one logical database from many physical servers.)
- Blackhole (accepts but does not store data. The functionality can be used in distributed database design where data is automatically replicated, but not stored locally. Can be used to perform performance tests)

```mysql
mysql> SHOW ENGINES
*************************** 1. row ***************************
      Engine: InnoDB
     Support: DEFAULT
     Comment: Supports transactions, row-level locking, and foreign keys
Transactions: YES
          XA: YES
  Savepoints: YES
*************************** 2. row ***************************
      Engine: CSV
     Support: YES
     Comment: CSV storage engine
Transactions: NO
          XA: NO
  Savepoints: NO
```


# Non relational

## Cloud in-memory
### Amazon ElasticCache
Cheaper as caching layer, no data durability, uses for caching in front of other DB.
Microsecond latencies for both reads and writes.
### Amazon MemoryDB for Redis
More expensive as caching layer since it has data durability and can be used as both cache and database. Microsecond read and single-digit millisecond write latency.

### ElasticCache vs MemoryDB vs DynamoDB vs DynamoDB+DAX

Amazon DynamoDB Accelerator (DAX) is a fully managed, highly available caching service built for [Amazon DynamoDB](https://aws.amazon.com/dynamodb/). DAX delivers up to a 10 times performance improvement—from milliseconds to microseconds—even at millions of requests per second.

Benefits - only several lines of code required to tune it within DynamoDB.(No application logic changes)

![[Cache comparison.png]]
## Cloud Key-value
### DynamoDB (Key-value)

Implements the concept of [[2. Basic Concepts and Theorems#Consistent hashing]]

Amazon DynamoDB is a serverless, fully managed NoSQL database that supports key-value and document data models. It offers single-digit millisecond latency and can scale up and down to serve more than 20 million requests per second. It also supports data ranging from 1 gigabyte to 1 petabyte, allowing developers to build demanding, responsive, scalable, and reliable applications.

## Non Cloud Key-Value
### ETCD
#### Lease
In etcd, a lease is a fundamental concept that represents a time-limited key-value pair. It's a mechanism used to manage and control resources, keys, or leadership in a distributed system.
- When a node or component in the distributed system creates a lease for a particular key, it gains ownership and control over that resource or key for the duration of the TTL. During this time, the node can read, write, or modify the associated key-value pair as needed.
- **Lease Renewal**: To extend its control over the resource, the node must periodically renew the lease by sending keep-alive requests to etcd before the TTL expires. As long as the node successfully renews the lease within the TTL, it retains ownership and control.

## Cloud Document
### DocumentDB with MongoDB compatibility
Amazon DocumentDB is a fully managed NoSQL database built for managing JSON data models. It offers a fully scalable, low latency service to manage mission-critical MongoDB workloads. It automatically replicates six copies of your data across 3 availability zones to offer a 99.99% availability. Additionally, it can serve millions of requests per second, enabling developers to build highly available and low latency applications.

## Wide column
[[1. Concepts#Wide-column stores]]
### Amazon Keyspaces(Cassandra–compatible)
TBD
### Google BigTable
TBD
### Apache HBase
An open-source, distributed, and scalable NoSQL database that is designed to handle large volumes of data with high write and read throughput. It is often used for storing and managing massive amounts of semi-structured or unstructured data, such as log files, sensor data, and other data types that require fast and random access.
### Cassandra DB
Implements the concept of [[2. Basic Concepts and Theorems#Consistent hashing]] 
Read more: [[1. Concepts#Wide-column stores]]
```CQL
SELECT column1, column2, ... FROM keyspace_name.table_name WHERE condition;
```
## Time series DB
### Amazon Timestamp
### InfluxDB
Known for its high performance and scalability, InfluxDB is often used for monitoring metrics, sensor data, and event logging. It supports continuous queries and retention policies for managing data over time.
### Prometheus
While primarily a monitoring and alerting system, Prometheus has its own time-series database optimized for collecting and querying metrics data. It's well-suited for cloud-native environments.
### OpenTSDB
OpenTSDB is an open-source, distributed time-series database built on top of HBase. It is used for storing and querying large amounts of time-series data.
### TimeScaleDB

TimescaleDB is an open-source database designed to make SQL scalable for time-series data. It is engineered up from PostgreSQL and packaged as a PostgreSQL extension, providing automatic partitioning across time and space (partitioning key), as well as full SQL support.
## Graph
#### Amazon Neptune
TBD
## Ledger
### Amazon Ledger Database Service (QLDB)
- No smart contracts, it focuses primarily on data integrity and auditing.
- 200 tps for read and write
### Use cases:
- Store financial transactions
	Create a complete and accurate record of all financial transactions, such as credit and debit transactions.
- Reconcile supply chain systems
	Record the history of each transaction and provide details of every batch manufactured, shipped, stored, and sold from facility to store.
- Maintain claims history
	Track a claim over its lifetime, and cryptographically verify data integrity to make the application resilient against data entry errors and manipulation.
- Centralize digital records
	Implement a system-of-record application to create a complete, centralized record of employee details such as payroll, bonus, and benefits.
# When to choose
## RDS vs Aurora vs Redshift
## RDS
1. OLTP
2. When you use other database engine than PostgreSQL or MySQL
3. When you use MySQL with other storage engine than InnoDB.
4. When you need version of MySQL/PostgreSQL that is not supported in Aurora
5. You want predictable database costs. RDS has the same pricing model as EC2; there’s a fixed per-hour cost for every instance you run.
6. Vendor lock - when you don't want to be fully dependent on Amazon for bug fixes or upgrades.
7. Check other RDS issues and limitations
## Aurora
1. OLTP
2. When you need better performance(5x compared to MySQL, 3x compared to PostgreSQL)
3. When you need better scalability and availability (RDS limits replicas to 5, while Aurora to 15)
4. Aurora Serverless is recommended for bursty workloads that spike up/down frequently
5. Check other Aurora issues and limitations
## Redshift
1. When you need Online Analytical Processing(OLAP)
2. When you need bigger storage limit(6PT in Redshift against 128TB in Aurora and 64TB in RDS)
3.  Check other Redshift issues and limitations

## DynamoDB vs DocumentDB
### When to choose DynamoDB
- When you need high-throughput key-value operations store, low-latency performance, and simple query patterns.
Use cases include session management, user profiles, and catalog systems.
### When to choose DocumentDB
- When you need MongoDB compatibility
- When you need complex queries(including ad-hoc), aggregations and indexing and further full text search on the JSON-like documents.
- When you have schema-less data structure.
Use cases include content management systems, product catalogs with varying attributes, and applications with evolving data schemas.
## DynamoDB vs ElasticCache(Redis)
### When to choose ElasticCache
- When you need fast, in-memory data storage with simple data structures and caching capabilities
### When to choose DynamoDB
- When you need advanced querying capabilities, including querying by primary key, secondary indexes, and complex query expressions
- When you need automatic scaling (Scaling ElastiCache may require more planning and management, especially when distributing data across multiple nodes or clusters.)
- When you need strong consistency(DynamoDB offers strong consistency by default, which ensures that you can read the most up-to-date data immediately after a write operation. Achieving strong consistency in ElastiCache requires careful configuration and can impact performance.)
- When you need a fully managed AWS service(ElastiCache, while managed, may require more manual management and maintenance)



# Pool
## Riak



## Memcached

## Redis (Remote Dictionary Serve)

