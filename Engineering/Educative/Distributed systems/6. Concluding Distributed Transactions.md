# Guarantees distributed systems should provide

### Consistency and durability guarantees

To achieve _durability_ in a distributed system, we should store data in more than one replicas before acknowledging, so that the system can survive the failures of a single node.

To achieve _consistency_, the system can introduce some additional read and write operations in the transaction’s context to guarantee the preservation of application consistency. These operations may be automatically generated, such as referential integrity constraints from foreign keys or cascades, or they may be defined by the application, e.g., via triggers.

### Atomicity and isolation guarantees

The guarantees of _atomicity_ and _isolation_ are more challenging to preserve, and we previously analyzed some of the algorithms we can use for this purpose.

## Combining algorithms to guarantee all properties

The algorithms must combine to guarantee all properties: _atomicity_, _consistency_, _isolation_, and _durability_.

Looking at the previous algorithms presented, it is easy to realize that some of them introduce either brittleness (e.g., two-phase commit) or a lot of additional complexity to a system (e.g., quorum-based commit).

The algorithms presented for _isolation_ can be used in both centralized and distributed systems. However, their use in a distributed system has several additional implications.

For example, _two-phase locking_ requires the use of distributed locks, which is something that is not trivial to implement in a distributed system.

Optimistic techniques, such as snapshot isolation, require a lot of data transfer between different nodes in a distributed system, which has adverse effects on performance.
### Conclusion
As a consequence, using transactions in a distributed system comes at a higher cost compared to a centralized system. So, systems that do not have a strong need for distributed systems can be designed to operate safely without them.

That is also one of the reasons why many distributed databases either do not provide full support for ACID transactions or force the user to opt in to use them explicitly.

# Long-Lived Transactions and Sagas

Achieving complete **isolation** between transactions is relatively expensive.

The system either has to maintain locks for each transaction and potentially block other concurrent transactions from making progress, or abort some transactions to maintain **safety**, which leads to some wasted effort.

## Long-lived transactions

These are transactions that by their nature have a longer duration in the order of hours or even days, instead of milliseconds. This can happen because this transaction processes a large amount of data, requires human input to proceed, or needs to communicate with third party systems that are slow.

Examples:
- Batch jobs that calculate reports over big datasets
- Claims at an insurance company, containing various stages that require human input
- An online order of a product that spans several days from order to delivery

## Saga

Sometimes, long-lived transactions do not really require full _isolation_ between each other, but they still need to be _atomic_, so that _consistency_ is maintained under partial failures. Thus, researchers came up with a new concept: the **saga**.

The _saga_ is a sequence of transactions T1​, T2​, …, Tn​ that can be interleaved with other transactions.

However, it’s guaranteed that either all of the transactions will succeed, or none of them will, maintaining the _atomicity_ guarantee.

Each transaction Ti​ is associated with a so-called compensating transaction Ci​, that is executed in case a rollback is needed.

### Benefits of the saga

Distributed transactions are generally hard and can only be achieved by making compromises on _performance_ and _availability_.

There are cases where we can use a saga transaction instead of a distributed transaction. This will satisfy all of our business requirements while keeping our systems loosely coupled and achieving good _availability_ and _performance_.

#### Example scenario

Let’s imagine we are building an e-commerce application, where every order of a customer requires several discrete steps: credit card authorization, checking warehouse inventory, item shipping, invoice creation and delivery, etc.

- One approach could be to perform a distributed transaction across all these systems for every order. However, in this case, the failure of a single component (i.e., the payment system) could potentially bring the whole system to a halt.
- An alternative, leveraging the saga pattern, would be to model the order operation as a saga operation, consisting of all these sub-transactions, where each of them is associated with a compensating transaction.

For example, debiting a customer’s bank account could have a compensating transaction that would give a refund. Then, we can build the order operation as a sequential execution of these transactions, as shown in the following transactions. In case any of these transactions fail, we can rollback the transactions that have been executed and run their corresponding compensating transactions.


![[saga.png]]

##### Cases where isolation is required

In the example above, orders from different customers about the same product might share some data, which can lead to interference between each other.

Think about the scenario of two concurrent orders A and B, where A has reserved the last item from the warehouse. As a result of this, order B fails at the first step and is rejected because of zero inventory.

To prevent these scenarios, some form of isolation can be introduced at the application layer.

## Providing isolation at the application layer

### Semantic lock

The use of a semantic lock essentially signals that some data items are currently in process and should be treated differently or not accessed at all. The final transaction of a _saga_ takes care of releasing this lock and resetting the data to its normal state.

### Commutative updates

The use of commutative updates that have the same effect regardless of their order of execution. This can help mitigate cases that are otherwise susceptible to lost update phenomena.

### Re-ordering the structure of the saga

Re-order the saga structure so that a transaction called a **pivot transaction** delineates a boundary between transactions that can fail and those that can’t.

In this way, transactions that can’t fail, but could lead to serious problems if rolled back due to failures of other transactions, can be moved after the _pivot transaction_.









