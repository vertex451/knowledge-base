# Achieving Serializability
There are different isolation levels that prevent anomalies. Stronger isolation levels prevent more anomalies at the cost of performance.
In the context of isolation, the execution of multiple transactions that correspond to an ordering of the associated operations is also called a **schedule**.
## Types of serializability
There are two major types of serializability:
- View serializability
	A schedule is a **view** equivalent to a serial schedule with the same transactions when all the operations from transactions in the two schedules read and write the same data values (“view”) the same data.
	View serializability guarantees that, even if a set of transactions is executed concurrently, the final state should be consistent with some serial order.
- Conflict serializability
	A schedule is a **conflict** equivalent to a serial schedule with the same transactions when every pair of conflicting operations between transactions is ordered in the same way in both schedules.

To understand conflict serializability, we first have to define what it means for two operations to be conflicting.
Two operations are conflicting if:
- They belong to different transactions
- They are on the same data item, and at least one of them is a write operation, where a write operation inserts, modifies or deletes an object

As a result, we can have three different forms of conflicts:
1. A read-write conflict
2. A write-read conflict
3. A write-write conflict
### Precedence graph
A practical way of determining whether a schedule is conflict serializable is through a **precedence graph** -  a directed graph, where the:
- **Nodes** represent transactions in a schedule
- **Edges** represent conflicts between operations

![[4. precedence-grapqh.png]]

As we can see in the above illustration, the conflicting operations in this schedule form a precedence graph _with_ a cycle. This means that this schedule is _not conflict serializable_. The cycle between T1​ and T2​ means that there must be a serial schedule where T1​ executes before T2​ and vice-versa, which is impossible.
## Mechanisms for concurrency control
### Pessimistic concurrency control
The name _pessimistic_ comes from the fact that this approach assumes that the majority of transactions are expected to conflict with each other, so appropriate measures are taken to prevent this from causing issues.

This approach blocks a transaction if it’s expected to cause violation of serializability, and resumes it when it is safe to do so.

This is usually achieved by having transactions acquire locks on the data they process to prevent other transactions from processing the same data concurrently.
### Optimistic concurrency control
This approach delays the checking of whether a transaction complies with the rules until the end of the transaction. The transaction is aborted if a commit would violate any serializability rules, and is then restarted and re-executed from the beginning.

The name “optimistic” comes from the fact that this approach assumes that the majority of transactions are expected not to have conflicts, so measures are taken only in the rare case that they do.

This can be the case for workloads with many read-only transactions and only a few write transactions, or in cases where most of the transactions touch different data.

**The main trade-off** between _pessimistic_ and _optimistic_ concurrency control is between the extra overhead from locking mechanisms, and the wasted computation from aborted transactions.

# Pessimistic Concurrency Control (PCC)

## 2-Phase locking (2PL)

is a pessimistic concurrency control protocol that uses locks to prevent concurrent transactions from interfering. These locks indicate that a record is being used by a transaction, so that other transactions can determine whether it is safe to use it or not.

There are two basic types of locks used in this protocol:
- **Write (exclusive) locks**: These locks are acquired when a record is going to be written (inserted/updated/deleted).
- **Read (shared) locks**: These locks are acquired when a record is read.
## Interaction between write (exclusive) locks and read (shared) locks
- A _read lock_ does not block a _read_ from another transaction. This is why it is also called _shared_ because multiple read locks can be acquired at the same time.
- A _read lock_ blocks a _write_ from another transaction. The other transaction will have to wait until the read operation is completed and the read lock is released. Then, it will have to acquire a write lock and perform the write operation.
- A _write_ lock blocks both _reads_ and _writes_ from other transactions, which is also the reason it’s also called _exclusive_. The other transactions will have to wait for the write operation to complete and the write lock to be released; then, they will attempt to acquire the proper lock and proceed.
If a lock blocks another lock, they are called **incompatible**. Otherwise, they are called **compatible**, so compatible are only read blocks.
## Deal with deadlocks
#### Prevention
This method prevents the deadlocks from being formed in the first place.
This can be done if transactions know all the locks they need in advance and acquire them in an ordered way. This is typically done by the application since many databases support interactive transactions and are thus unaware of all the data a transaction will access.
#### Detection
This method detects deadlocks that occur, and breaks them. For example, this can be achieved by keeping track of which transaction a transaction waits on, using this information to detect cycles that represent deadlocks, and then forcing one of these transactions to abort. This is typically done by the database, without the application having to do anything extra.
# Optimistic Concurrency Control (OCC)
In this method, transactions execute in the following three phases:
## Begin
In this phase, transactions are assigned a unique timestamp that marks the beginning of the transaction.
## Read & modify
During this phase, transactions execute their read and write operations _tentatively_. This means that when an item is modified, a copy of the item is written to a temporary, local storage location. A read operation first checks for a copy of the item in this location and returns this one, if it exists. Otherwise, it performs a regular read operation from the database.
## Validate & commit/rollback

The transaction enters this phase when all operations have been executed.

During this phase, the transaction checks whether there are other transactions that have modified the data this transaction has accessed, and have started after this transaction’s start time. If there are, then the transaction is aborted and restarted from the beginning, acquiring a new timestamp. Otherwise, the transaction can be committed.

It’s important to note that the validation checks and the associated commit operation need to be performed in a single atomic action as part of a critical section.

### Ways to implement validation logic

#### Version checking

Where every data item is marked with a version number. Every time a transaction accesses an item, it can keep track of the version number it had at that point.

During the validation phase, the transaction can check if the version number is the same. If it is, it would mean that no other transaction has accessed the item in the meanwhile.

#### Timestamp ordering

In this approach, each transaction keeps track of the items that are accessed by read or write operations, known as the **read set** and the **write set**.

During validation transaction records a fresh timestamp, called the **finish timestamp**, and iterates over all the transactions that have been assigned a timestamp between the transaction’s start and finish timestamp.

For each of those transactions, the running transaction checks if their _write set_ intersects with its own _read set_. If that’s true for any of these transactions, it means that the transaction essentially reads a value “from the future.”

As a result, the transaction is invalid and must be aborted and restarted from the beginning with a fresh timestamp. Otherwise, the transaction is committed, and is assigned the next timestamp.

# Achieving Snapshot Isolation

## Multi-version concurrency control (MVCC)

**Multiversion Concurrency Control (MVCC)** is a technique where multiple physical versions are maintained for a single logical data item. As a result, update operations do not overwrite existing records, but they write a new version of these records. Read operations can then select a specific version of a record, possibly an older one.

It can be used, theoretically, with both _optimistic_ and _pessimistic_ schemes. 
However, most variations use an optimistic concurrency control method to leverage the multiple versions of an item from transactions that run concurrently.

## Achieving snapshot isolation using MVCC

_Snapshot isolation_ (SI) is an isolation level that guarantees that all reads made in a transaction see a consistent snapshot of the database from the point it started, and the transaction commits successfully if no other transaction has updated the same data since that snapshot.

This works in the following way:

- Each transaction is assigned a unique timestamp at the beginning.
- Every entry for a data item contains a version that corresponds to the timestamp of the transaction that created this new version.
- Every transaction records the following pieces of information during its beginning:
    - The transaction with the highest timestamp that has committed so far (say, Ts)
    - The number of active transactions that have started but haven’t been committed yet
#### Performing a read operation

When performing a read operation for an item, a transaction returns the entry with the latest version that is earlier than Ts and does not belong to one of the transactions that were active at the beginning of this transaction. 

This prevents dirty reads, as only committed values from other transactions can be returned.

There is an exception to this rule: if the transaction has already updated this item, then this value is returned instead.

#### Performing a write operation

When performing a write operation for an item, a transaction checks whether there is an entry for the same item that satisfies one of the following criteria: its version is higher than this transaction’s timestamp, or its version is lower than this transaction’s timestamp, but this version belongs to one of the transactions that were active at the beginning of this transaction.

In any of these cases, the transaction is aborted and can be restarted from scratch with a larger timestamp.

## Not all anomalies can be prevented in MVCC

# Achieving Full Serializable Snapshot Isolation

SI states this: in the precedence graph of any non-serializable execution, there are two **rw-dependency** edges that form consecutive edges in a cycle. These involve two transactions that have been active concurrently.



