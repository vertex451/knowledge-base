# DS

A **distributed system** is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another

# Benefits of DS
- Performance(Problem with a single computer)
Distributed systems allow us to achieve better performance at a lower cost.
- Scalability
- Availability
# Fallacies of distributed computing
- The network is reliable
- The network is secure
- Latency is zero
	There’s a large difference (from milliseconds to nanoseconds) in latency between a call to a remote system and that to local memory access.
- Transport cost is zero
	Serialization and Deserialization, Encryption and decryption,  Message Routing and Addressing consume computational resources and time, contributing to the overall transport cost.
- The global clock fallacy
	(False) “Distributed systems have a global clock, which we can use to identify when events happen.” To mitigate this, we can use TrueTime API built by Google
- Topology doesn’t change
- Bandwidth is infinite
	This fallacy is weaker nowadays, but this is important to consider when we make decisions about our distributed system’s topology, and when requests travel through the Internet.

# Properties that make distributed systems challenging
- Network asynchrony
	Messages might take extremely long to deliver in a distributed system. They may even deliver out of order—or not at all
- Partial failures
- Concurrency
	computations at the same time can interfere with each other and create unexpected behaviors

# Measures of Correctness
### Safety
A safety property defines something that **must never happen** in a correct system (the oven not exceeding a maximum temperature threshold)
### Liveness
A liveness property defines something that must eventually happen in a correct system (the oven eventually reaching the temperature we specified via the button)

# Categories of distributed systems
1.  Synchronous systems
	much easier to describe and program. 
2. Asynchronous systems
	Is closer to real-life distributed systems, such as the Internet, where we cannot control all the components they involve
# Types of Failures
- Fail-stop
	A node halts and remains halted permanently. 
- Crash
	A node restarts, but silently. Other nodes may not be able to detect this state.
- Omission
	A node fails to respond to incoming requests.
- Byzantine
	Node does not behave according to its specific protocol or algorithm. Usually happens when a malicious actor or a software bug compromises the node.
# Avoiding multiple deliveries of a message
The sender node may deliver a message multiple times because the receipt can be lost due to the network fail.
## Idempotent operations approach
**Idempotent** is an operation we can apply multiple times without changing the result beyond the initial application.
Example: Adding a value to map(if there is no process which removes values)
## De-duplication approach
In the de-duplication approach, we give every message a unique identifier, and every retried message contains the same identifier as the original, and receiver will ignore repeated messages. 
**In order to do this, we must have control on both sides of the system: sender and receiver.**
## Difference between delivery and processing
**Delivery** is the arrival of the message at the destination node, at the hardware level.
**Processing** is the handling of this message from the software application layer of the node.
In most cases, we care more about how many times a node processes a message, than about how many times it receives it.

It’s impossible to have _exactly-once delivery_ in a distributed system. However, it’s still sometimes possible to have _exactly-once processing._
We can easily implement **at-most-once** delivery semantics and **at-least-once** delivery semantics.
# Fundamental problem in the field of distributed systems.
It is very hard to differentiate between a crashed node and a node that is just really slow to respond to requests.
The main mechanism we can use to detect it is **Timeout**

But here comes trade off, depends of the timeout duration:
- in case of a small timeout time the system will waste less time waiting for the nodes that have crashed, but it might declare some nodes as crashed, while they are actually just a bit slower than expected.
- in case of a big timeout time the system will be more lenient with slow nodes, but it will be slower in identifying crashed nodes, in some cases wasting time while waiting for them.
## Failure detector
A failure detector is the component of a node that we can use to identify other nodes that have failed.
Properties:
- **Completeness** corresponds to the percentage of crashed nodes a failure detector successfully identifies in a certain period.
- **Accuracy** corresponds to the number of mistakes a failure detector makes in a certain period.
# Stateless and Stateful Systems
The main difference - nodes from stateless system are identical, which makes this system scalable, fault tolerant and simpler to handle.

It’s usually wise to create an architecture that contains clear boundaries between stateless components (which perform business capabilities) and stateful components (which handle data).

Also, to achieve stateless, such parts as session, client specific cache and state itself are moved to the client side.














